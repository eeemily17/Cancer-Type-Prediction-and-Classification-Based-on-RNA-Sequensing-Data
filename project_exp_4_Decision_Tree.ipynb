{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and class label\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "dflabels = pd.read_csv('project_class_labels_45.csv',index_col='Unnamed: 0')\n",
    "processeddf = pd.read_csv('project_data_down_45.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1485, 20301)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see if there is any feature (i.e. column) has all zero values so we will delete them\n",
    "removedAllZeroColdf = processeddf.loc[:, (processeddf != 0).any(axis=0)]\n",
    "removedAllZeroColdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1485, 6636)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Selection - Variance Threshold \n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=500000)\n",
    "reduced = sel.fit_transform(removedAllZeroColdf)\n",
    "reduceddf = DataFrame(reduced)\n",
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20291</th>\n",
       "      <th>20292</th>\n",
       "      <th>20293</th>\n",
       "      <th>20294</th>\n",
       "      <th>20295</th>\n",
       "      <th>20296</th>\n",
       "      <th>20297</th>\n",
       "      <th>20298</th>\n",
       "      <th>20299</th>\n",
       "      <th>20300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.192484</td>\n",
       "      <td>-0.755906</td>\n",
       "      <td>0.446054</td>\n",
       "      <td>-0.593338</td>\n",
       "      <td>-0.633973</td>\n",
       "      <td>-0.038358</td>\n",
       "      <td>-0.363468</td>\n",
       "      <td>-0.659568</td>\n",
       "      <td>-0.100470</td>\n",
       "      <td>-0.104769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.754288</td>\n",
       "      <td>-0.163153</td>\n",
       "      <td>0.630883</td>\n",
       "      <td>-0.294233</td>\n",
       "      <td>-0.597323</td>\n",
       "      <td>-1.256714</td>\n",
       "      <td>-1.302928</td>\n",
       "      <td>-0.436749</td>\n",
       "      <td>-0.386928</td>\n",
       "      <td>-0.110039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.192484</td>\n",
       "      <td>-0.638706</td>\n",
       "      <td>-0.720695</td>\n",
       "      <td>-0.229807</td>\n",
       "      <td>1.717049</td>\n",
       "      <td>-0.038358</td>\n",
       "      <td>-0.593566</td>\n",
       "      <td>-0.659568</td>\n",
       "      <td>-0.100470</td>\n",
       "      <td>-0.141879</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.219220</td>\n",
       "      <td>-0.858947</td>\n",
       "      <td>-0.597955</td>\n",
       "      <td>-0.303946</td>\n",
       "      <td>-0.718719</td>\n",
       "      <td>-0.951909</td>\n",
       "      <td>-0.669963</td>\n",
       "      <td>-0.965714</td>\n",
       "      <td>0.493859</td>\n",
       "      <td>-0.176391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.192484</td>\n",
       "      <td>-0.719361</td>\n",
       "      <td>-0.624723</td>\n",
       "      <td>-0.810700</td>\n",
       "      <td>1.421606</td>\n",
       "      <td>-0.038358</td>\n",
       "      <td>-0.223596</td>\n",
       "      <td>0.248409</td>\n",
       "      <td>-0.100470</td>\n",
       "      <td>-0.120959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.982288</td>\n",
       "      <td>-0.875488</td>\n",
       "      <td>-0.513379</td>\n",
       "      <td>-0.288079</td>\n",
       "      <td>-0.787315</td>\n",
       "      <td>-1.166562</td>\n",
       "      <td>-0.067199</td>\n",
       "      <td>-1.252016</td>\n",
       "      <td>0.876467</td>\n",
       "      <td>-0.052508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.192484</td>\n",
       "      <td>-0.525673</td>\n",
       "      <td>-0.569783</td>\n",
       "      <td>-0.575637</td>\n",
       "      <td>-0.875379</td>\n",
       "      <td>-0.038358</td>\n",
       "      <td>-0.700962</td>\n",
       "      <td>2.190311</td>\n",
       "      <td>-0.100470</td>\n",
       "      <td>-0.147639</td>\n",
       "      <td>...</td>\n",
       "      <td>1.406053</td>\n",
       "      <td>0.620178</td>\n",
       "      <td>0.097046</td>\n",
       "      <td>-0.295408</td>\n",
       "      <td>-0.093643</td>\n",
       "      <td>-1.259139</td>\n",
       "      <td>-0.906240</td>\n",
       "      <td>-0.183397</td>\n",
       "      <td>0.955710</td>\n",
       "      <td>3.459447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.521522</td>\n",
       "      <td>-0.712481</td>\n",
       "      <td>-0.671541</td>\n",
       "      <td>-0.761510</td>\n",
       "      <td>4.970730</td>\n",
       "      <td>-0.038358</td>\n",
       "      <td>-0.905740</td>\n",
       "      <td>-0.659568</td>\n",
       "      <td>0.612594</td>\n",
       "      <td>-0.147639</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.220881</td>\n",
       "      <td>-1.397227</td>\n",
       "      <td>-0.589230</td>\n",
       "      <td>-0.260070</td>\n",
       "      <td>-0.788476</td>\n",
       "      <td>-1.083691</td>\n",
       "      <td>-1.070452</td>\n",
       "      <td>-1.122174</td>\n",
       "      <td>-0.186059</td>\n",
       "      <td>-0.176391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6      \\\n",
       "0 -0.192484 -0.755906  0.446054 -0.593338 -0.633973 -0.038358 -0.363468   \n",
       "1 -0.192484 -0.638706 -0.720695 -0.229807  1.717049 -0.038358 -0.593566   \n",
       "2 -0.192484 -0.719361 -0.624723 -0.810700  1.421606 -0.038358 -0.223596   \n",
       "3 -0.192484 -0.525673 -0.569783 -0.575637 -0.875379 -0.038358 -0.700962   \n",
       "4  2.521522 -0.712481 -0.671541 -0.761510  4.970730 -0.038358 -0.905740   \n",
       "\n",
       "      7         8         9        ...        20291     20292     20293  \\\n",
       "0 -0.659568 -0.100470 -0.104769    ...    -0.754288 -0.163153  0.630883   \n",
       "1 -0.659568 -0.100470 -0.141879    ...    -1.219220 -0.858947 -0.597955   \n",
       "2  0.248409 -0.100470 -0.120959    ...    -0.982288 -0.875488 -0.513379   \n",
       "3  2.190311 -0.100470 -0.147639    ...     1.406053  0.620178  0.097046   \n",
       "4 -0.659568  0.612594 -0.147639    ...    -1.220881 -1.397227 -0.589230   \n",
       "\n",
       "      20294     20295     20296     20297     20298     20299     20300  \n",
       "0 -0.294233 -0.597323 -1.256714 -1.302928 -0.436749 -0.386928 -0.110039  \n",
       "1 -0.303946 -0.718719 -0.951909 -0.669963 -0.965714  0.493859 -0.176391  \n",
       "2 -0.288079 -0.787315 -1.166562 -0.067199 -1.252016  0.876467 -0.052508  \n",
       "3 -0.295408 -0.093643 -1.259139 -0.906240 -0.183397  0.955710  3.459447  \n",
       "4 -0.260070 -0.788476 -1.083691 -1.070452 -1.122174 -0.186059 -0.176391  \n",
       "\n",
       "[5 rows x 20301 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data scaling\n",
    "# method 1 : standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdscaler = StandardScaler()\n",
    "stdscalerfit = stdscaler.fit_transform(removedAllZeroColdf)\n",
    "\n",
    "stddf = DataFrame(stdscalerfit)\n",
    "stddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 80% training set; 20% testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainData, testData, trainLabel, testLabel = train_test_split(reduceddf, dflabels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree-entrophy training time:  42.34432935714722\n",
      "Accuracy Score (entrophy decision tree): 0.717171717172\n",
      "[[5 0 0 ..., 0 0 0]\n",
      " [0 7 0 ..., 1 0 0]\n",
      " [0 1 8 ..., 0 1 0]\n",
      " ..., \n",
      " [0 0 1 ..., 6 2 0]\n",
      " [0 0 0 ..., 0 5 0]\n",
      " [0 0 0 ..., 0 0 6]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ACC       0.50      0.83      0.62         6\n",
      "       BLCA       0.64      0.78      0.70         9\n",
      "       BRCA       0.80      0.73      0.76        11\n",
      "       CESC       0.83      0.56      0.67         9\n",
      "       CHOL       0.50      0.40      0.44        10\n",
      "       COAD       0.73      0.57      0.64        14\n",
      "       DLBC       1.00      1.00      1.00         9\n",
      "       ESCA       0.75      0.75      0.75         8\n",
      "        GBM       1.00      0.78      0.88         9\n",
      "       HNSC       0.64      0.70      0.67        10\n",
      "       KICH       0.58      0.85      0.69        13\n",
      "       KIRC       0.78      0.50      0.61        14\n",
      "       KIRP       1.00      0.83      0.91         6\n",
      "       LAML       1.00      1.00      1.00         5\n",
      "        LGG       1.00      1.00      1.00         9\n",
      "       LIHC       0.55      0.75      0.63         8\n",
      "       LUAD       0.73      0.53      0.62        15\n",
      "       LUSC       0.70      0.64      0.67        11\n",
      "       MESO       0.60      1.00      0.75         6\n",
      "         OV       1.00      0.88      0.93         8\n",
      "       PAAD       0.75      0.43      0.55         7\n",
      "       PCPG       0.75      0.86      0.80         7\n",
      "       PRAD       1.00      0.89      0.94         9\n",
      "       READ       0.40      0.57      0.47         7\n",
      "       SARC       0.54      0.58      0.56        12\n",
      "       SKCM       0.86      0.55      0.67        11\n",
      "       STAD       0.67      0.80      0.73         5\n",
      "       TGCT       0.56      1.00      0.71         5\n",
      "       THCA       0.91      0.91      0.91        11\n",
      "       THYM       1.00      0.75      0.86         8\n",
      "       UCEC       0.60      0.55      0.57        11\n",
      "        UCS       0.50      0.62      0.56         8\n",
      "        UVM       0.75      1.00      0.86         6\n",
      "\n",
      "avg / total       0.74      0.72      0.72       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "# measure training time\n",
    "import time\n",
    "\n",
    "entrophy_clf = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "            min_samples_leaf=1,min_samples_split=2, \n",
    "            min_weight_fraction_leaf=0.0)\n",
    "start = time.time()\n",
    "entrophy_clf = entrophy_clf.fit(trainData, trainLabel)\n",
    "end = time.time()\n",
    "print(\"decision tree-entrophy training time: \", end - start)\n",
    "\n",
    "pred = entrophy_clf.predict(testData)\n",
    "accuracy = accuracy_score(testLabel, pred)\n",
    "print(\"Accuracy Score (entrophy decision tree):\", accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(testLabel, pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "# classficiation report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(testLabel, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
